# setting: advanced-realistic
# method: reward-penalty, posterior

# Please update env.dataset to dataset path, env.mesh_parent_path to house folder

# Please update agent.out_folder to the path of the output folder

# Please update train.actor_path, train.critic_path to the path of the sim-trained actor and critic

env:
  venv_seed: 42
  name: advanced-realistic
  dataset: data/advanced_realistic_ps_train_1000.pkl
  action_dim: 2
  action_mag: 1.0
  use_append: true
  obs_buffer: 0.25
  g_x_fail: 0.25
  terminal_type: const
  img_h: 90
  img_w: 160
  max_step_train: 200
  max_step_eval: 200
  obs_channel: 12
  fixed_init: true
  sparse_reward: false
  num_env_train: 1000
  reward_type: all
  reward_goal: 5
  reward_wander: 1
  reward_obs: -10
  #
  mesh_parent_path: data/3d-front-house-meshes
  fill_obs: false
  camera_tilt: 15
  camera_tilt_range: [15, 25]
  camera_roll_noise_std: 3
  perf_xdot_range: [0.5, 1.0]
  backup_xdot_range: [0.2, 0.5]

agent:
  use_wandb: false
  device: cuda:0
  image_device: cpu
  num_cpus: 10
  num_gpu_envs: 5
  cpu_offset: 0
  seed: 42
  entity: pac-saferl
  project: naive_rl
  run: base_advanced_realistic
  out_folder: result/base_advanced_realistic
  name: NaiveStackRL
  save_top_k: 20
  save_metric: perf
  max_steps: 3000000
  memory_capacity: 5000
  check_opt_freq: 8
  min_steps_b4_opt: 40000
  optimize_freq: 20000
  update_per_opt: 1000
  num_visualize_task: 1
  num_traj_per_visual_init: 1
  num_validation_trajs: 100
  check_type: random
  plot_v: true
  random_init: true
  #
  use_append_noise: true
  nu: 1.0
  nu_decay: 0.50
  nu_period: 50000
  l_x_noise_std: 2.0
  heading_noise_std: 1.0
  #
  traj_size: 4
  frame_skip: 3

train:
  eval: false
  device: cuda:0
  latent_dim: 0
  latent_dim_cnn: 0
  batch_size: 128
  update_period: 1
  alpha: 0.5
  learn_alpha: false
  gamma: 0.99
  gamma_schedule: false
  lr_a: 0.0003
  lr_al: 0.001
  lr_c: 0.0003
  lr_a_schedule: false
  lr_c_schedule: false
  mode: performance
  tau: 0.01
  terminal_type: none
  actor_path: ?
  critic_path: ?

arch:
  critic_has_act_ind: false
  act_ind:
    - 1
  activation:
    actor: ReLU
    critic: ReLU
  kernel_size:
  - 7
  - 5
  - 3
  stride:
  - 4
  - 3
  - 2
  n_channel:
  - 16
  - 32
  - 64
  mlp_dim:
    actor:
    - 256
    - 256
    - 256
    critic:
    - 256
    - 256
    - 256
  append_dim: 2
  use_bn: false
  use_ln: true
  use_sm: false
